{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-17T08:18:15.352050Z","iopub.status.busy":"2024-05-17T08:18:15.351052Z","iopub.status.idle":"2024-05-17T08:19:43.108338Z","shell.execute_reply":"2024-05-17T08:19:43.107389Z","shell.execute_reply.started":"2024-05-17T08:18:15.352013Z"},"trusted":true},"outputs":[],"source":["#Import necessary libraries\n","import torch\n","from torch import nn\n","import pandas as pd\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import copy\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","from wandb.keras import WandbCallback\n","import socket\n","socket.setdefaulttimeout(30)\n","!pip install wandb\n","import wandb\n","wandb.login()\n","wandb.init(project ='AttentionRNN')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:43.193799Z","iopub.status.busy":"2024-05-17T08:19:43.193471Z","iopub.status.idle":"2024-05-17T08:19:43.367120Z","shell.execute_reply":"2024-05-17T08:19:43.365994Z","shell.execute_reply.started":"2024-05-17T08:19:43.193775Z"},"trusted":true},"outputs":[],"source":["# Set device to GPU if available, otherwise CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","#loading data\n","train_csv = \"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv\"\n","val_csv = \"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv\"\n","test_csv = \"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv\"\n","\n","# Load training, validation, and testing data\n","#Train data\n","train_data = pd.read_csv(train_csv, header=None)\n","train_input = train_data[0].to_numpy()\n","train_output = train_data[1].to_numpy()\n","\n","#Validation data\n","val_data = pd.read_csv(val_csv,header = None)\n","val_input = val_data[0].to_numpy()\n","val_output = val_data[1].to_numpy()\n","\n","#Test data\n","test_data = pd.read_csv(test_csv,header= None)\n","test_input = test_data[0].to_numpy()\n","test_output = test_data[1].to_numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:43.389174Z","iopub.status.busy":"2024-05-17T08:19:43.388388Z","iopub.status.idle":"2024-05-17T08:19:51.496092Z","shell.execute_reply":"2024-05-17T08:19:51.494866Z","shell.execute_reply.started":"2024-05-17T08:19:43.389138Z"},"trusted":true},"outputs":[],"source":["\n","# Preprocess the training data\n","def pre_processing(train_input,train_output,split,scale):\n","    data = {\n","        \"all_characters\" : [], #List of unique characters in the source data\n","        \"char_num_map\" : {}, #Mapping from character to numerical index for source data\n","        \"num_char_map\" : {}, #Mapping from numerical index to character for source data\n","        \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device), #Tensor to store numerical indices of source characters\n","        \"source_data\" : train_input, #Store the original source input data\n","        \"all_characters_2\" : [], #List of unique characters in the target data\n","        \"char_num_map_2\" : {}, #Mapping from character to numerical index for target data\n","        \"num_char_map_2\" : {}, #Mapping from numerical index to character for target data\n","        \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device), #Tensor to store numerical indices of target characters\n","        \"target_data\" : train_output, #Store the original target output data\n","        \"source_len\" : 0, #Length of unique characters in source data\n","        \"target_len\" : 0 #Length of unique characters in target data\n","    }\n","\n","    # Initialize a temporary index counter\n","    temp = 0\n","    for i in range(0,len(train_input)):\n","        # Pad the input strings to a fixed length of 30 characters with '{'\n","        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n","        charToNum = [] # List to store numerical indices of characters for the current input string\n","        for char in (train_input[i]):\n","            index = 0 # Initialize index\n","            if(char not in data[\"all_characters\"]):\n","                # Add new characters to the list and create mappings\n","                data[\"all_characters\"].append(char)\n","                index = data[\"all_characters\"].index(char)\n","                split=split+1\n","                if(split==10):\n","                    scale=10\n","            if(char not in data[\"all_characters\"]):\n","                # Update the mappings if the character is not already mapped\n","                data[\"char_num_map\"][char] = index\n","                data[\"num_char_map\"][index] = char\n","                scale=scale-1\n","                if(scale<0):\n","                    scale=5\n","            else:\n","                # Use the existing index if the character is already mapped\n","                index = data[\"all_characters\"].index(char)\n","            # Append the index to the list\n","            charToNum.append(index)\n","            \n","        my_tensor = torch.tensor(charToNum,device = device) # Convert the list to a tensor\n","        data[\"source_charToNum\"][temp] = my_tensor # Store the tensor in the data dictionary\n","        \n","         # List to store numerical indices of characters for the current output string\n","        charToNum1 = []\n","        \n","        # Pad the output strings to a fixed length of 23 characters with '{'\n","        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n","        for char in (train_output[i]):\n","            index = 0\n","            if(char not in data[\"all_characters_2\"]):\n","                # Add new characters to the list and create mappings\n","                data[\"all_characters_2\"].append(char)\n","                index = data[\"all_characters_2\"].index(char)\n","                if(scale<10):\n","                    if(split==5):\n","                        scale=scale*2\n","            if(char not in data[\"all_characters_2\"]):\n","                # Update the mappings if the character is not already mapped\n","                data[\"char_num_map_2\"][char] = index\n","                data[\"num_char_map_2\"][index] = char\n","                if(split==10):\n","                    split=1\n","            else:\n","                # Use the existing index if the character is already mapped\n","                index = data[\"all_characters_2\"].index(char)\n","                \n","            charToNum1.append(index)\n","            \n","        my_tensor1 = torch.tensor(charToNum1,device = device)\n","        data[\"val_charToNum\"][temp] = my_tensor1 # Store the tensor in the data dictionary\n","        \n","        temp+=1  # Increment the index counter\n","    if(temp>=0):\n","        # Update the lengths of unique characters in source and target data\n","        data[\"source_len\"] = len(data[\"all_characters\"])\n","        data[\"target_len\"] = len(data[\"all_characters_2\"])\n","        \n","    return data # Return the processed data dictionary\n","\n","# Call the pre_processing function with copies of the train input and output data\n","data = pre_processing(copy.copy(train_input),copy.copy(train_output),10,100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:51.506774Z","iopub.status.busy":"2024-05-17T08:19:51.506206Z","iopub.status.idle":"2024-05-17T08:19:52.064098Z","shell.execute_reply":"2024-05-17T08:19:52.062966Z","shell.execute_reply.started":"2024-05-17T08:19:51.506746Z"},"trusted":true},"outputs":[],"source":["#Same line comments as above\n","def pre_processing_validation(val_input,val_output,split,batch):\n","    data2 = {\n","        \"all_characters\" : [],\n","        \"char_num_map\" : {},\n","        \"num_char_map\" : {},\n","        \"source_charToNum\": torch.zeros(len(val_input),30, dtype=torch.int, device=device),\n","        \"source_data\" : val_input,\n","        \"all_characters_2\" : [],\n","        \"char_num_map_2\" : {},\n","        \"num_char_map_2\" : {},\n","        \"val_charToNum\": torch.zeros(len(val_output),23, dtype=torch.int, device=device),\n","        \"target_data\" : val_output,\n","        \"source_len\" : 0,\n","        \"target_len\" : 0\n","    }\n","    temp = 0\n","    \n","    map1 = data[\"char_num_map\"]\n","    map2 = data[\"char_num_map_2\"]\n","    \n","    for i in range(0,len(val_input)):\n","        val_input[i] = \"{\" + val_input[i] + \"}\"*(29-len(val_input[i]))\n","        charToNum = []\n","        for char in (val_input[i]):\n","            index = 0\n","            if(char not in data2[\"all_characters\"]):\n","                data2[\"all_characters\"].append(char)\n","                index = map1[char]\n","            if(char not in data2[\"all_characters\"]):\n","                data2[\"char_num_map\"][char] = index\n","                data2[\"num_char_map\"][index] = char\n","            else:\n","                index = map1[char]\n","            \n","            charToNum.append(index)\n","            \n","        my_tensor = torch.tensor(charToNum,device = device)\n","        data2[\"source_charToNum\"][k] = my_tensor\n","        \n","        charToNum1 = []\n","        val_output[i] = \"{\" + val_output[i] + \"}\"*(22-len(val_output[i]))\n","        for char in (val_output[i]):\n","            index = 0\n","            if(char not in data2[\"all_characters_2\"]):\n","                data2[\"all_characters_2\"].append(char)\n","                index = map2[char]\n","                data2[\"char_num_map_2\"][char] = index\n","                data2[\"num_char_map_2\"][index] = char\n","            else:\n","                index = map2[char]\n","                \n","            charToNum1.append(index)\n","            \n","        my_tensor1 = torch.tensor(charToNum1,device = device)\n","        data2[\"val_charToNum\"][temp] = my_tensor1\n","        \n","        temp+=1\n","    \n","    data2[\"source_len\"] = len(data2[\"all_characters\"])\n","    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n","        \n","    return data2\n","    \n","data2 = pre_processing_validation(copy.copy(val_input),copy.copy(val_output),10,100)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:52.065715Z","iopub.status.busy":"2024-05-17T08:19:52.065415Z","iopub.status.idle":"2024-05-17T08:19:52.072756Z","shell.execute_reply":"2024-05-17T08:19:52.071612Z","shell.execute_reply.started":"2024-05-17T08:19:52.065692Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, x,y):\n","        self.source = x\n","        self.target = y\n","    def __len__(self):\n","        return len(self.source)\n","    def __getitem__(self, idx):\n","        source_data = self.source[idx]\n","        target_data = self.target[idx]\n","        return source_data, target_data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:52.097653Z","iopub.status.busy":"2024-05-17T08:19:52.096950Z","iopub.status.idle":"2024-05-17T08:19:52.118586Z","shell.execute_reply":"2024-05-17T08:19:52.117492Z","shell.execute_reply.started":"2024-05-17T08:19:52.097621Z"},"trusted":true},"outputs":[],"source":["def heat_map_generation(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n","    \n","    data3 = pre_processing_validation(copy.copy(test_input),copy.copy(test_output))\n","    \n","    dataset = MyDataset(data3[\"source_charToNum\"],data3['val_charToNum'])\n","    dataLoader = DataLoader(dataset, batch_size=batchsize, shuffle=True)\n","    \n","    encoder.eval()\n","    decoder.eval()\n","    \n","    validation_accuracy = 0\n","    validation_loss = 0\n","    \n","    lossFunction = nn.NLLLoss()\n","    \n","    \n","    \n","    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n","        \n","        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n","            \n","        if(bidirection == \"Yes\"):\n","            reversed_batch = torch.flip(sourceBatch, dims=[1]) # reverse the batch across rows.\n","            sourceBatch = (sourceBatch + reversed_batch)//2 # adding reversed data to source data by averaging\n","\n","        if(cellType == 'LSTM'):\n","            encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n","\n","        encoderStates , encoderOutput = encoder(sourceBatch,encoder_initial_state)\n","\n","        decoderCurrentState = encoderOutput # this selects the last state from encoder states\n","\n","        encoderFinalLayerStates = encoderStates[:, -1, :, :]\n","\n","        \n","\n","        loss = 0 # decoder starts\n","            \n","        outputSeqLen = targetBatch.shape[1] # here you will get as name justified. 40\n","        \n","        Output = []\n","        #print(targetBatch)\n","\n","        randNumber = random.random()\n","        \n","        for i in range(0,outputSeqLen):\n","            \n","            if(i == 0):\n","                decoderCurrentInput = torch.full((batchsize,1),0, device=device)\n","                #decoder_input_tensor = targetBatch[:, i].reshape(batchsize,1) #32*1\n","                #print(dec_input_tensor.shape)\n","            else:\n","                if randNumber < tf_ratio:\n","                    decoderCurrentInput = targetBatch[:, i].reshape(batchsize, 1)\n","                    #decoder_input_tensor = targetBatch[:, i].reshape(batchsize, 1) # current batch is passed\n","                else:\n","                    decoderCurrentInput = decoderCurrentInput.reshape(batchsize, 1)\n","                    #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n","\n","            decoderOutput, decoderCurrentState, attentionWeights = decoder(decoderCurrentInput, decoderCurrentState, encoderFinalLayerStates)\n","            \n","            for j in range (0,10):\n","                temp = []\n","                if(i<length[j]):\n","                    for k in range(0,30):\n","                        temp.append(attentionWeights[j][0][k].item())\n","                    attentions[j].append(temp)\n","                \n","            dummy, topi = decoderOutput.topk(1)\n","    \n","            decoderOutput = decoderOutput[:, -1, :]\n","            curr_target_chars = targetBatch[:, i] #(32)\n","            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n","            loss+=(lossFunction(decoderOutput, curr_target_chars))\n","\n","            decoderCurrentInput = topi.squeeze().detach()\n","            Output.append(decoderCurrentInput)\n","\n","            # tensor_2d = torch.stack(Output)\n","            # Output = tensor_2d.t() #it is outside the for loop\n","        validation_loss += (loss.item()/outputSeqLen)\n","\n","        break\n","        tensor_2d = torch.stack(Output)\n","        Output = tensor_2d.t()\n","        \n","        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n","        \n","        if(batch_num%40 == 0):\n","            print(\"bt:\", batch_num, \" loss:\", loss.item()/outputSeqLen)\n","            #'k'/24\n","            # here you get the actual word letters seqeunces softamx indeces\n","            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n","            #correct = (Output == targetBatch).all(dim=1).sum().item()\n","            #accuracy = accuracy + correct    \n","    for i in range (0,10):\n","        for j in range (0,30):\n","            print(attentions[0][i][j])\n","    'l'/24\n","    encoder.train()\n","    decoder.train()\n","    print(\"validation_accuracy\",validation_accuracy/40.96)\n","    print(\"validation_loss\",validation_loss)\n","#     wandb.log({'validation_accuracy':validation_accuracy/40.96})\n","#     wandb.log({'validation_loss':validation_loss})"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:52.120867Z","iopub.status.busy":"2024-05-17T08:19:52.120393Z","iopub.status.idle":"2024-05-17T08:19:52.141516Z","shell.execute_reply":"2024-05-17T08:19:52.140378Z","shell.execute_reply.started":"2024-05-17T08:19:52.120830Z"},"trusted":true},"outputs":[],"source":["def validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n","    \n","    # Create a data loader for the validation set with the specified batch size\n","    dataLoader = dataLoaderFun(\"validation\",batchsize) # dataLoader depending on train or validation\n","    \n","    # Set the encoder and decoder to evaluation mode\n","    encoder.eval()\n","    decoder.eval()\n","    \n","    # Initialize validation accuracy and loss to zero\n","    validation_accuracy = 0\n","    validation_loss = 0\n","    \n","    # Define the loss function as Negative Log Likelihood Loss\n","    lossFunction = nn.NLLLoss()\n","    \n","    # Iterate over each batch in the data loader\n","    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n","        #hiddenlayers * BatchSize * Neurons\n","        # Get the initial hidden state for the encoder\n","        encoder_initial_state = encoder.getInitialState() \n","            \n","        # If using bidirectional RNN, process the source batch accordingly\n","        if(bidirection != \"No\"):\n","            # Reverse the source batch along the sequence dimension\n","            reversed_batch = torch.flip(sourceBatch, dims=[1])\n","            # Average the original and reversed batches\n","            sourceBatch = (sourceBatch + reversed_batch)//2\n","\n","        if(cellType == 'LSTM'):\n","             # If using LSTM, adjust the initial state for LSTM\n","            encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n","\n","        # Pass the source batch through the encoder\n","        encoderStates , encoderOutput = encoder(sourceBatch,encoder_initial_state)\n","\n","        # Initialize the decoder's current state with the encoder's output\n","        decoderCurrentState = encoderOutput\n","\n","        # Get the final states of the encoder's layers\n","        encoderFinalLayerStates = encoderStates[:, -1, :, :]\n","\n","        # List to store attention weights for analysis\n","        attentions = []\n","\n","        loss = 0\n","            \n","        # Length of the output sequence (target sequence length)\n","        outputSeqLen = targetBatch.shape[1]\n","        \n","        Output = []\n","\n","        # Generate a random number for teacher forcing decision\n","        randNumber = random.random()\n","\n","\n","        for i in range(0,outputSeqLen):\n","            \n","            if(i == 0):\n","                # For the first time step, use the start token as input\n","                decoderCurrentInput = torch.full((batchsize,1),0, device=device)\n","            else:\n","                if randNumber >= tf_ratio:\n","                    # Use the previous decoder output as input\n","                    decoderCurrentInput = decoderCurrentInput.reshape(batchsize, 1)\n","                else:\n","                    # Use the current target character (teacher forcing)\n","                    decoderCurrentInput = targetBatch[:, i].reshape(batchsize, 1)\n","                    \n","             # Pass the current input and state through the decoder\n","            decoderOutput, decoderCurrentState, attentionWeights = decoder(decoderCurrentInput, decoderCurrentState, encoderFinalLayerStates)\n","\n","            # Store the attention weights\n","            attentions.append(attentionWeights)\n","            dummy, topi = decoderOutput.topk(1)\n","            \n","            # Use the last time step's output for loss calculation\n","            decoderOutput = decoderOutput[:, -1, :]\n","            curr_target_chars = targetBatch[:, i] #(32)\n","            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n","            loss+=(lossFunction(decoderOutput, curr_target_chars)) # Accumulate the loss for the current time step\n","\n","            decoderCurrentInput = topi.squeeze().detach()\n","            Output.append(decoderCurrentInput)\n","\n","        validation_loss += (loss.item()/outputSeqLen) # Accumulate the average loss for the current batch\n","        \n","        tensor_2d = torch.stack(Output)\n","        Output = tensor_2d.t()\n","        \n","        # Calculate and accumulate the accuracy for the current batch\n","        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n","        \n","        if(batch_num%40 == 0):\n","            print(\"bt:\", batch_num, \" loss:\", loss.item()/outputSeqLen)    \n","    # Set the encoder and decoder back to training mode \n","    encoder.train()\n","    decoder.train()\n","    #print(\"val_accuracy\",validation_accuracy/4096)\n","    #print(\"val_loss\",validation_loss)\n","    # wandb.log({'val_accuracy':validation_accuracy/4096})\n","    # wandb.log({'val_loss':validation_loss})"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:52.147436Z","iopub.status.busy":"2024-05-17T08:19:52.146597Z","iopub.status.idle":"2024-05-17T08:19:52.157584Z","shell.execute_reply":"2024-05-17T08:19:52.156658Z","shell.execute_reply.started":"2024-05-17T08:19:52.147401Z"},"trusted":true},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, hiddenSize):\n","        super(Attention, self).__init__()\n","        self.Watt = nn.Linear(hiddenSize, hiddenSize)\n","        self.Uatt = nn.Linear(hiddenSize, hiddenSize)\n","        self.Vatt = nn.Linear(hiddenSize, 1)\n","\n","    def forward(self, query, keys):\n","        calc = self.Watt(query) + self.Uatt(keys)\n","        scores = self.Vatt(torch.tanh(calc))\n","        scores = scores.squeeze().unsqueeze(1)\n","        weights = F.softmax(scores, dim=0)\n","        weights = weights.permute(2,1,0)\n","        keys = keys.permute(1,0,2)\n","        context = torch.bmm(weights, keys)\n","        return context, weights"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:52.159718Z","iopub.status.busy":"2024-05-17T08:19:52.159164Z","iopub.status.idle":"2024-05-17T08:19:52.189875Z","shell.execute_reply":"2024-05-17T08:19:52.188958Z","shell.execute_reply.started":"2024-05-17T08:19:52.159681Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    \n","    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n","        super(Encoder, self).__init__()\n","        #Define embedding layer\n","        self.embedding = nn.Embedding(inputDim, embSize)\n","        self.encoderLayers = encoderLayers\n","        self.hiddenLayerNuerons = hiddenLayerNuerons\n","        self.batch_size = batch_size\n","        self.cellType = cellType\n","        # Initialize the appropriate RNN type based on cellType\n","        if(cellType=='GRU'):\n","            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n","        elif(cellType=='RNN'):\n","            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n","        else:\n","            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n","\n","    def forward(self,sourceBatch,encoderCurrState):\n","        # Get the sequence length from the source batch\n","        sequenceLength = len(sourceBatch[0])\n","        # Initialize tensor to store encoder states\n","        encoderStates = torch.zeros(sequenceLength,self.encoderLayers,self.batch_size,self.hiddenLayerNuerons,device=device)\n","        # Iterate over each time step in the sequence\n","        for i in range(0,sequenceLength):\n","            # Get the current input at time step i\n","            currInput = sourceBatch[:,i].reshape(self.batch_size,1)\n","            # Calculate the current states using the statesCalculation method\n","            dummy , encoderCurrState = self.statesCalculation(currInput,encoderCurrState)\n","            if(self.cellType != 'LSTM'):\n","                encoderStates[i] = encoderCurrState\n","            else: \n","                encoderStates[i] = encoderCurrState[1]\n","\n","        # Return the encoder states and the current state of the encoder\n","        return encoderStates ,encoderCurrState\n","\n","\n","    def statesCalculation(self, currentInput, prevState):\n","        embdInput = self.embedding(currentInput) # Embed the current input\n","        # Pass the embedded input and previous state through the RNN\n","        output, prev_state = self.rnn(embdInput, prevState)\n","        return output, prev_state\n","    \n","    def getInitialState(self):\n","        # Return a tensor of zeros as the initial state\n","        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n","    \n","class Decoder(nn.Module):\n","    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n","        super(Decoder, self).__init__()\n","        # Define embedding layer\n","        self.embedding = nn.Embedding(outputDim, embSize)\n","        self.cellType=cellType\n","        # Initialize the appropriate RNN type based on cellType\n","        #For GRU\n","        if(cellType == 'GRU'):\n","            self.rnn = nn.GRU(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n","        #For RNN\n","        elif(cellType == 'RNN'):\n","            self.rnn = nn.RNN(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n","        #For LSTM\n","        else:\n","            self.rnn = nn.LSTM(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n","        \n","        #Used mapping to vocabulary\n","        # Define fully connected layer for output projection\n","        self.fc = nn.Linear(hiddenLayerNuerons, outputDim)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        self.dropout = nn.Dropout(dropout_p)\n","        # Initialize attention mechanism\n","        self.attention = Attention(hiddenLayerNuerons).to(device)\n","\n","    def forward(self, current_input, prev_state,encoder_final_layers):\n","        # Compute context vector and attention weights\n","        if(self.cellType == 'LSTM'):\n","            context , attn_weights = self.attention(prev_state[1][-1,:,:], encoder_final_layers)\n","        else:\n","            context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)\n","        # Embed the current input\n","        embd_input = self.embedding(current_input)\n","        curr_embd = F.relu(embd_input)\n","        #Input of GRU\n","        # Concatenate the embedded input and context vector\n","        input_gru = torch.cat((curr_embd, context), dim=2)\n","        output, prev_state = self.rnn(input_gru, prev_state)\n","        # Apply dropout to the output\n","        output = self.dropout(output)\n","        # Apply the fully connected layer and softmax to get the final output\n","        output = self.softmax(self.fc(output)) \n","        return output, prev_state, attn_weights"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:59.879129Z","iopub.status.busy":"2024-05-17T08:19:59.878816Z","iopub.status.idle":"2024-05-17T08:19:59.885866Z","shell.execute_reply":"2024-05-17T08:19:59.884815Z","shell.execute_reply.started":"2024-05-17T08:19:59.879100Z"},"trusted":true},"outputs":[],"source":["def dataLoaderFun(dataName,batch_size):\n","    if(dataName == 'train'):\n","        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    else:\n","        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n","        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:59.887889Z","iopub.status.busy":"2024-05-17T08:19:59.887297Z","iopub.status.idle":"2024-05-17T08:19:59.909564Z","shell.execute_reply":"2024-05-17T08:19:59.908672Z","shell.execute_reply.started":"2024-05-17T08:19:59.887863Z"},"trusted":true},"outputs":[],"source":["def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n","    # Add optimizer and teacher forcing ratio to wandb parameters\n","    \n","    # Initialize the data loader for the training data\n","    dataLoader = dataLoaderFun(\"train\",batchsize) # dataLoader depending on train or validation\n","    \n","    encoder = Encoder(data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n","    decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n","    \n","    # Initialize the optimizer for the encoder and decoder\n","    if(optimizer == 'Adam'):\n","        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n","        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n","    else:\n","        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n","        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n","    \n","    # Define the loss function as Negative Log Likelihood Loss\n","    lossFunction = nn.NLLLoss()\n","\n","    for epoch in range (0,epochs):\n","        \n","         # Initialize training accuracy and loss\n","        train_accuracy = 0 \n","        train_loss = 0 \n","\n","        for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n","                        \n","            # Get the initial hidden state for the encoder\n","            encoderInitialState = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n","            \n","            # Process the source batch if using bidirectional RNN\n","            if(bidirection == \"Yes\"):\n","                reversed_batch = torch.flip(sourceBatch, dims=[1]) # Reverse the source batch across the sequence dimension\n","                sourceBatch = (sourceBatch + reversed_batch)//2 # Average the original and reversed batches\n","            \n","            # Adjust the initial state for LSTM\n","            if(cellType == 'LSTM'):\n","                encoderInitialState = (encoderInitialState, encoder.getInitialState())\n","                \n","            # Pass the source batch through the encoder\n","            encoderStates,EcoderOutput= encoder(sourceBatch,encoderInitialState)\n","\n","            # Get the final states of the encoder's layers\n","            encoderFinalLayerStates = encoderStates[:, -1, :, :] # this selects the hidden top layers from each sequence\n","\n","            # Initialize the decoder's current state with the encoder's output\n","            decoderCurrentState = EcoderOutput            \n","            attentions = []\n","            loss = 0 # decoder starts\n","            \n","            # Get the length of the output sequence\n","            outputSeqLen = targetBatch.shape[1]\n","            \n","            Output = []\n","            \n","            # Generate a random number for teacher forcing decision\n","            randNumber = random.random()\n","\n","            # Iterate over each time step in the output sequence\n","            for i in range(0,outputSeqLen):\n","\n","                if(i == 0):\n","                    # For the first time step, use the start token as input\n","                    decoderCurrentInput = torch.full((batchsize,1),0, device=device)\n","                else:\n","                    if randNumber >= tf_ratio:\n","                        # Use the previous decoder output as input\n","                        decoderCurrentInput = decoderCurrentInput.reshape(batchsize, 1)\n","                    else:\n","                        # Use the current target character (teacher forcing)\n","                        decoderCurrentInput = targetBatch[:, i].reshape(batchsize, 1)\n","                \n","                # Pass the current input and state through the decoder\n","                decoderOutput, decoderCurrentState, attentionWeights = decoder(decoderCurrentInput, decoderCurrentState, encoderFinalLayerStates)\n","                \n","                # Get the top prediction from the decoder output\n","                temporary, topIndeces = decoderOutput.topk(1)\n","\n","                # Use the last time step's output for loss calculation\n","                decoderOutput = decoderOutput[:, -1, :]\n","                curr_target_chars = targetBatch[:, i]\n","                curr_target_chars = curr_target_chars.type(dtype=torch.long)\n","                loss+=(lossFunction(decoderOutput, curr_target_chars)) # Accumulate the loss for the current time step\n","\n","                # Update the decoder input for the next time step\n","                decoderCurrentInput = topIndeces.squeeze().detach()\n","                Output.append(decoderCurrentInput)\n","\n","                attentions.append(attentionWeights)\n","\n","            # Stack the outputs and transpose to match the target batch shape\n","            tensor_2d = torch.stack(Output)\n","            Output = tensor_2d.t() \n","            train_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n","\n","            # Accumulate the average loss for the current batch\n","            train_loss += (loss.item()/outputSeqLen)\n","                \n","            # Zero the gradients for the optimizer\n","            encoderOptimizer.zero_grad()\n","            decoderOptimizer.zero_grad()\n","            #Backpropagation\n","            loss.backward()\n","            # Update the parameters\n","            encoderOptimizer.step()\n","            decoderOptimizer.step()\n","        \n","        #Log accuracies loss and wandb\n","        print(\"train_accuracy\",train_accuracy/51200)\n","        print(\"train_loss\",train_loss)\n","        wandb.log({'train_accuracy':train_accuracy/51200})\n","        wandb.log({'train_loss':train_loss})\n","        wandb.log({'epoch':epoch})\n","        validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T08:19:59.911268Z","iopub.status.busy":"2024-05-17T08:19:59.910740Z"},"trusted":true},"outputs":[],"source":["def main_fun():\n","    wandb.init(project ='AttentionRNN')\n","    params = wandb.config\n","    with wandb.init(project = 'AttentionRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n","        train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n","    \n","sweep_params = {\n","    'method' : 'bayes',\n","    'name'   : 'CS6910_assignment3_attention',\n","    'metric' : {\n","        'goal' : 'maximize',\n","        'name' : 'validation_accuracy',\n","    },\n","    'parameters' : {\n","        'embSize':{'values':[16,32,64]},\n","        'encoderLayers':{'values':[1,5,10]},\n","        'decoderLayers' : {'values' : [1,5,10]},\n","        'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n","        'cellType' : {'values' : ['LSTM'] } ,\n","        'bidirection' : {'values' : ['no','Yes']},\n","        'dropout' : {'values' : [0,0.2,0.3]},\n","        'epochs'  : {'values': [10,15]},\n","        'batchsize' : {'values' : [32,64]},\n","        'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n","        'optimizer':{'values' : ['Adam','Nadam']},\n","        'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n","    }\n","}\n","sweepId = wandb.sweep(sweep_params,project = 'AttentionRNN')\n","wandb.agent(sweepId,function =main_fun)\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Plotting heat map\n","#Plotting Hindi vs English words\n","import matplotlib.pyplot as plt\n","def plot_attention_heatmap(attention_matrix, input_sequence, output_sequence , id):\n","\n","    plt.figure(figsize=(15, 10))\n","\n","    ax = sns.heatmap(attention_matrix, cmap='viridis', annot=False, xticklabels=input_sequence, yticklabels=output_sequence)\n","\n","    # Set font properties for Hindi characters\n","    font_path = '/kaggle/input/fonts-bro-1/NotoSansHindi-VariableFont_wdth,wght.ttf'  # Replace with the path to a Hindi font file\n","    hindi_font = FontProperties(fname=font_path)\n","\n","    ax.set_xticklabels(input_sequence, fontproperties=hindi_font)\n","    ax.set_yticklabels(output_sequence, fontproperties=hindi_font)\n","\n","    ax.set_xlabel('Input Sequence')\n","    ax.set_ylabel('Output Sequence')\n","    plt.title('Attention Heatmap')\n","    wandb.log({\"Attention_Heatmap\"+str(id)+ \"temp\": wandb.Image(plt)})\n","\n","    plt.close()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5025118,"sourceId":8436661,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
