{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:02:45.640710Z","iopub.status.busy":"2024-05-17T05:02:45.640363Z","iopub.status.idle":"2024-05-17T05:03:22.623786Z","shell.execute_reply":"2024-05-17T05:03:22.621929Z","shell.execute_reply.started":"2024-05-17T05:02:45.640681Z"},"trusted":true},"outputs":[],"source":["#Import necessary libraries\n","import torch\n","from torch import nn\n","import pandas as pd\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import copy\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","from wandb.keras import WandbCallback\n","import socket\n","socket.setdefaulttimeout(30)\n","!pip install wandb\n","import wandb\n","wandb.login()\n","wandb.init(project ='VanillaRNN')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:22.701633Z","iopub.status.busy":"2024-05-17T05:03:22.700799Z","iopub.status.idle":"2024-05-17T05:03:22.711840Z","shell.execute_reply":"2024-05-17T05:03:22.711024Z","shell.execute_reply.started":"2024-05-17T05:03:22.701600Z"},"trusted":true},"outputs":[],"source":["# Set device to GPU if available, otherwise CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","#loading data\n","train_csv = \"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv\"\n","val_csv = \"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv\"\n","test_csv = \"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv\"\n","\n","# Load training, validation, and testing data\n","#Train data\n","train_data = pd.read_csv(train_csv, header=None)\n","train_input = train_data[0].to_numpy()\n","train_output = train_data[1].to_numpy()\n","#Validation data\n","val_data = pd.read_csv(val_csv,header = None)\n","val_input = val_data[0].to_numpy()\n","val_output = val_data[1].to_numpy()\n","#Test data\n","test_data = pd.read_csv(test_csv,header= None)\n","test_input = test_data[0].to_numpy()\n","test_output = test_data[1].to_numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:22.878393Z","iopub.status.busy":"2024-05-17T05:03:22.878135Z","iopub.status.idle":"2024-05-17T05:03:30.392636Z","shell.execute_reply":"2024-05-17T05:03:30.391641Z","shell.execute_reply.started":"2024-05-17T05:03:22.878370Z"},"trusted":true},"outputs":[],"source":["\n","# Preprocess the training data\n","def pre_processing(train_input,train_output,split,scale):\n","    data = {\n","        \"all_characters\" : [], #List of unique characters in the source data\n","        \"char_num_map\" : {}, #Mapping from character to numerical index for source data\n","        \"num_char_map\" : {}, #Mapping from numerical index to character for source data\n","        \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device), #Tensor to store numerical indices of source characters\n","        \"source_data\" : train_input, #Store the original source input data\n","        \"all_characters_2\" : [], #List of unique characters in the target data\n","        \"char_num_map_2\" : {}, #Mapping from character to numerical index for target data\n","        \"num_char_map_2\" : {}, #Mapping from numerical index to character for target data\n","        \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device), #Tensor to store numerical indices of target characters\n","        \"target_data\" : train_output, #Store the original target output data\n","        \"source_len\" : 0, #Length of unique characters in source data\n","        \"target_len\" : 0 #Length of unique characters in target data\n","    }\n","\n","    # Initialize a temporary index counter\n","    temp = 0\n","    for i in range(0,len(train_input)):\n","        # Pad the input strings to a fixed length of 30 characters with '{'\n","        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n","        charToNum = [] # List to store numerical indices of characters for the current input string\n","        for char in (train_input[i]):\n","            index = 0 # Initialize index\n","            if(char not in data[\"all_characters\"]):\n","                # Add new characters to the list and create mappings\n","                data[\"all_characters\"].append(char)\n","                index = data[\"all_characters\"].index(char)\n","                split=split+1\n","                if(split==10):\n","                    scale=10\n","            if(char not in data[\"all_characters\"]):\n","                # Update the mappings if the character is not already mapped\n","                data[\"char_num_map\"][char] = index\n","                data[\"num_char_map\"][index] = char\n","                scale=scale-1\n","                if(scale<0):\n","                    scale=5\n","            else:\n","                # Use the existing index if the character is already mapped\n","                index = data[\"all_characters\"].index(char)\n","            # Append the index to the list\n","            charToNum.append(index)\n","            \n","        my_tensor = torch.tensor(charToNum,device = device) # Convert the list to a tensor\n","        data[\"source_charToNum\"][temp] = my_tensor # Store the tensor in the data dictionary\n","        \n","         # List to store numerical indices of characters for the current output string\n","        charToNum1 = []\n","        \n","        # Pad the output strings to a fixed length of 23 characters with '{'\n","        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n","        for char in (train_output[i]):\n","            index = 0\n","            if(char not in data[\"all_characters_2\"]):\n","                # Add new characters to the list and create mappings\n","                data[\"all_characters_2\"].append(char)\n","                index = data[\"all_characters_2\"].index(char)\n","                if(scale<10):\n","                    if(split==5):\n","                        scale=scale*2\n","            if(char not in data[\"all_characters_2\"]):\n","                # Update the mappings if the character is not already mapped\n","                data[\"char_num_map_2\"][char] = index\n","                data[\"num_char_map_2\"][index] = char\n","                if(split==10):\n","                    split=1\n","            else:\n","                # Use the existing index if the character is already mapped\n","                index = data[\"all_characters_2\"].index(char)\n","                \n","            charToNum1.append(index)\n","            \n","        my_tensor1 = torch.tensor(charToNum1,device = device)\n","        data[\"val_charToNum\"][temp] = my_tensor1 # Store the tensor in the data dictionary\n","        \n","        temp+=1  # Increment the index counter\n","    if(temp>=0):\n","        # Update the lengths of unique characters in source and target data\n","        data[\"source_len\"] = len(data[\"all_characters\"])\n","        data[\"target_len\"] = len(data[\"all_characters_2\"])\n","        \n","    return data # Return the processed data dictionary\n","\n","# Call the pre_processing function with copies of the train input and output data\n","data = pre_processing(copy.copy(train_input),copy.copy(train_output),10,100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:30.403736Z","iopub.status.busy":"2024-05-17T05:03:30.403105Z","iopub.status.idle":"2024-05-17T05:03:30.948187Z","shell.execute_reply":"2024-05-17T05:03:30.947032Z","shell.execute_reply.started":"2024-05-17T05:03:30.403703Z"},"trusted":true},"outputs":[],"source":["#Comments are same as above code.\n","def pre_processing_validation(validInput,validOutput,split,batch):\n","    data2 = {\n","        \"all_characters\" : [],\n","        \"all_characters_2\" : [],\n","        \"char_num_map_2\" : {},\n","        \"num_char_map_2\" : {},\n","        \"val_charToNum\": torch.zeros(len(validOutput),23, dtype=torch.int, device=device),\n","        \"source_charToNum\": torch.zeros(len(validInput),30, dtype=torch.int, device=device),\n","        \"target_data\" : validOutput,\n","        \"source_len\" : 0,\n","        \"source_data\" : validInput,\n","        \"target_len\" : 0,\n","        \"char_num_map\" : {},\n","        \"num_char_map\" : {}\n","    }\n","    temp = 0\n","    split=split\n","    map1 = data[\"char_num_map\"]\n","    map2 = data[\"char_num_map_2\"]\n","    \n","    for i in range(0,len(validInput)):\n","        validInput[i] = \"{\" + validInput[i] + \"}\" * (29-len(validInput[i]))\n","        charToNum = []\n","        for char in (validInput[i]):\n","            index = 0\n","            if(char not in data2[\"all_characters\"]):\n","                data2[\"all_characters\"].append(char)\n","                index = map1[char]\n","                split=batch+1\n","                if(split==0):\n","                    split=1\n","            if(char not in data2[\"all_characters\"]):\n","                data2[\"char_num_map\"][char] = index\n","                data2[\"num_char_map\"][index] = char\n","                batch=split-1\n","                if(batch==1):\n","                    batch=2\n","            else:\n","                index = map1[char]\n","            batch=batch/1\n","            charToNum.append(index)\n","            \n","        my_tensor = torch.tensor(charToNum,device = device)\n","        data2[\"source_charToNum\"][temp] = my_tensor\n","        \n","        charToNum1 = []\n","        validOutput[i] = \"{\" + validOutput[i] + \"}\"*(22-len(validOutput[i]))\n","        for char in (validOutput[i]):\n","            index = 0\n","            if(char not in data2[\"all_characters_2\"]):\n","                data2[\"all_characters_2\"].append(char)\n","                index = map2[char]\n","                split=split-2\n","                if(split<0):\n","                    if(scale==1):\n","                        split=1\n","            if(char not in data2[\"all_characters_2\"]):\n","                data2[\"char_num_map_2\"][char] = index\n","                data2[\"num_char_map_2\"][index] = char\n","                batch=batch+2\n","            else:\n","                index = map2[char]\n","            if(batch==1):\n","                if(split==10):\n","                    split=split-1\n","            charToNum1.append(index)\n","            \n","        my_tensor1 = torch.tensor(charToNum1,device = device)\n","        data2[\"val_charToNum\"][temp] = my_tensor1\n","        \n","        temp+=1\n","        scale=scale*2\n","        if(scale>512):\n","            scale=scale/512\n","    data2[\"source_len\"] = len(data2[\"all_characters\"])\n","    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n","        \n","    return data2\n","    \n","    \n","data2 = pre_processing_validation(copy.copy(validInput),copy.copy(validOutput),10,100)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:30.950243Z","iopub.status.busy":"2024-05-17T05:03:30.949559Z","iopub.status.idle":"2024-05-17T05:03:30.959170Z","shell.execute_reply":"2024-05-17T05:03:30.958202Z","shell.execute_reply.started":"2024-05-17T05:03:30.950204Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, x,y):\n","        self.source = x\n","        self.target = y\n","    def __len__(self):\n","        return len(self.source)\n","    def __getitem__(self, idx):\n","        source_data = self.source[idx]\n","        target_data = self.target[idx]\n","        return source_data, target_data\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:30.975243Z","iopub.status.busy":"2024-05-17T05:03:30.974966Z","iopub.status.idle":"2024-05-17T05:03:30.993948Z","shell.execute_reply":"2024-05-17T05:03:30.992430Z","shell.execute_reply.started":"2024-05-17T05:03:30.975221Z"},"trusted":true},"outputs":[],"source":["def validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n","    \n","    # Initialize data loader for validation data with the given batch size\n","    dataLoader = dataLoaderFun(\"validation\",batchsize)\n","    \n","    encoder.eval() # Set encoder to evaluation mode\n","    decoder.eval() # Set decoder to evaluation mode\n","    \n","    #Initialize validation accuracy and loss\n","    validation_accuracy = 0\n","    validation_loss = 0\n","    \n","    lossFunction = nn.NLLLoss() # Define the loss function (Negative Log Likelihood Loss)\n","    \n","    # Iterate over batches from the data loader\n","    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n","        \n","        # Get the initial state for the encoder\n","        encoderInitialState = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n","\n","        if(cellType=='LSTM'):\n","            # Handle initial state for LSTM cells\n","            encoderInitialState = (encoderInitialState,encoder.getInitialState())\n","            \n","        if(bidirection == \"Yes\"):\n","            # Reverse the source batch for bidirectional RNN\n","            reversed_batch = torch.flip(sourceBatch, dims=[1])\n","            # Average original and reversed batch\n","            sourceBatch = (sourceBatch + reversed_batch)//2 \n","        \n","        # Initialize list to store decoder outputs\n","        Output = []\n","        #Pass through encoder\n","        encoder_output, encoderCurrentState = encoder(sourceBatch,encoderInitialState)\n","\n","        # Initialize loss for the current batch\n","        loss = 0\n","\n","        outputSeqLen = targetBatch.shape[1] #length of the output sequence\n","        decoderCurrState = encoderCurrentState\n","\n","        # Generate a random number for teacher forcing ratio\n","        randNumber = random.random()\n","\n","        match = []\n","        for i in range(0,outputSeqLen):\n","\n","            if(i == 0):\n","                decoderInputensor = targetBatch[:, i].reshape(batchsize,1) # First input to the decoder is the start token\n","            else:\n","                if randNumber >= tf_ratio:\n","                    #Prev decoder output\n","                    decoderInputensor = decoderInputensor.reshape(batchsize, 1)\n","                else:\n","                    #Actual target value\n","                    decoderInputensor = targetBatch[:, i].reshape(batchsize, 1)\n","\n","            #Forward pass through decoder\n","            decoderOutput, decoderCurrState = decoder(decoderInputensor,decoderCurrState)\n","            dummy, topIndeces = decoderOutput.topk(1)\n","\n","            #Reshape the decoder output\n","            decoderOutput = decoderOutput[:, -1, :]\n","\n","            curr_target_chars = targetBatch[:, i] # Get current target characters\n","            curr_target_chars = curr_target_chars.type(dtype=torch.long) # Ensure target characters are long type\n","            loss+=(lossFunction(decoderOutput, curr_target_chars)) # Accumulate loss\n","            \n","            decoderInputensor = topIndeces.squeeze().detach()\n","            #Softmax values\n","            Output.append(decoderInputensor)\n","\n","        # Stack the list of outputs into a tensor\n","        tensor_2d = torch.stack(Output)\n","        Output = tensor_2d.t() # Transpose the tensor to match the target batch shape\n","\n","        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item() # it is simple just summing up the equal values\n","        validation_loss += (loss.item()/outputSeqLen)\n","    \n","    #Set back encoder to training mode\n","    encoder.train()\n","    decoder.train()\n","    #Print accuracies and wandb log\n","    print(\"validation_accuracy\",validation_accuracy/40.96)\n","    print(\"validation_loss\",validation_loss)\n","    wandb.log({'validation_accuracy':validation_accuracy/40.96})\n","    wandb.log({'validation_loss':validation_loss})"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:31.007674Z","iopub.status.busy":"2024-05-17T05:03:31.007286Z","iopub.status.idle":"2024-05-17T05:03:31.026660Z","shell.execute_reply":"2024-05-17T05:03:31.025556Z","shell.execute_reply.started":"2024-05-17T05:03:31.007639Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    \n","    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(inputDim, embSize) # Embedding layer to convert input indices to embeddings\n","        self.encoderLayers = encoderLayers # Number of layers in the RNN\n","        self.hiddenLayerNuerons = hiddenLayerNuerons # Number of neurons in each hidden layer\n","        self.batch_size = batch_size # Batch size for input data\n","        \n","        if(cellType=='GRU'):\n","            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True) #GRU Cell\n","        elif(cellType=='RNN'):\n","            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True) #Vanilla RNN Cell\n","        else:\n","            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True) #LSTM Cell\n","            \n","    def forward(self, currentInput, prevState):\n","        embdInput = self.embedding(currentInput) # Convert input indices to embeddings\n","        return self.rnn(embdInput, prevState) # Forward pass through the RNN\n","    \n","    def getInitialState(self):\n","        # Return initial hidden state for the encoder\n","        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n","    \n","class Decoder(nn.Module):\n","    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(outputDim, embSize) # Embedding layer to convert output indices to embeddings\n","        \n","        # Define the RNN cell type based on the provided cellType parameter\n","        if(cellType == 'RNN'):\n","            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n","        elif(cellType == 'LSTM'):\n","            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n","        else:\n","            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n","            \n","         # Fully connected layer to map RNN outputs to vocabulary\n","        self.fc = nn.Linear(hiddenLayerNuerons, outputDim)\n","        # LogSoftmax activation function\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        self.dropout = nn.Dropout(dropout_p) # Dropout layer for regularization\n","\n","    def forward(self, currentInput, prevState):\n","        embdInput = self.embedding(currentInput) # Convert input indices to embeddings\n","        currEmbd = F.relu(embdInput) # Apply ReLU activation to embeddings\n","        output, prevState = self.rnn(currEmbd, prevState) # Forward pass through the RNN\n","        # Apply dropout to the RNN output\n","        output = self.dropout(output)\n","        # Apply fully connected layer and softmax activation\n","        output = self.softmax(self.fc(output)) \n","        return output, prevState # Return the output and the updated state"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:38.961479Z","iopub.status.busy":"2024-05-17T05:03:38.961092Z","iopub.status.idle":"2024-05-17T05:03:38.970668Z","shell.execute_reply":"2024-05-17T05:03:38.969742Z","shell.execute_reply.started":"2024-05-17T05:03:38.961444Z"},"trusted":true},"outputs":[],"source":["#Data loader function\n","def dataLoaderFun(dataName,batch_size):\n","    #Select based on data sets\n","    if(dataName == 'validation'):\n","        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n","        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    elif(dataName == 'train'):\n","        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    else:\n","        dataset = MyDataset(data3[\"source_charToNum\"],data3['val_charToNum'])\n","        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:38.973514Z","iopub.status.busy":"2024-05-17T05:03:38.972827Z","iopub.status.idle":"2024-05-17T05:03:38.995664Z","shell.execute_reply":"2024-05-17T05:03:38.994611Z","shell.execute_reply.started":"2024-05-17T05:03:38.973483Z"},"trusted":true},"outputs":[],"source":["def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n","    \n","    #Data loader based on training\n","    dataLoader = dataLoaderFun(\"train\",batchsize)\n","    \n","    lossFunction = nn.NLLLoss()\n","    \n","    # Initialize encoder and decoder\n","    encoder = Encoder(data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n","    decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n","    \n","    # Initialize optimizer for encoder and decoder\n","    if(optimizer != 'Adam'):\n","        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n","        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n","    else:\n","        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n","        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n","    \n","    epoch=0\n","    while(epoch<epochs):\n","    \n","        train_accuracy = 0 \n","        train_loss = 0 \n","\n","        for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n","            \n","            #hiddenlayers * BatchSize * Neurons\n","            # Initialize initial state for encoder\n","            encoderInitialState = encoder.getInitialState()\n","            \n","            # Apply bidirectional processing if specified\n","            if(bidirection == \"Yes\"):\n","                reversed_batch = torch.flip(sourceBatch, dims=[1])\n","            if(bidirection != \"No\"):\n","                #Averaging data\n","                sourceBatch = (sourceBatch + reversed_batch)//2\n","            \n","            # Adjust initial state for LSTM cell\n","            if(cellType == 'LSTM'):\n","                encoderInitialState = (encoderInitialState, encoder.getInitialState())\n","                \n","            # Forward pass through encoder\n","            encoder_output, encoderCurrentState = encoder(sourceBatch,encoderInitialState)\n","            \n","            loss = 0 #Initialize loss\n","            \n","            sequenceLen = targetBatch.shape[1]\n","\n","            Output = []\n","            \n","            randNumber = random.random()\n","\n","            decoderCurrState = encoderCurrentState\n","\n","            for i in range(0,sequenceLen):\n","                \n","                if(i == 0):\n","                    decoderInput = targetBatch[:, i].reshape(batchsize,1)\n","                else:\n","                    if randNumber >= tf_ratio:\n","                        #Prev decoder output\n","                        decoderInput = decoderInput.reshape(batchsize, 1)\n","                    else:\n","                        #Actual target value\n","                        decoderInput = targetBatch[:, i].reshape(batchsize, 1)\n","                \n","                #Forward pass through decoder\n","                decoderOutput, decoderCurrState = decoder(decoderInput,decoderCurrState)\n","                dummy, topIndeces = decoderOutput.topk(1)     \n","                        \n","                #Resizing\n","                decoderOutput = decoderOutput[:, -1, :]\n","                targetChars = targetBatch[:, i]\n","\n","                #Find target characters\n","                targetChars = targetChars.type(dtype=torch.long)\n","\n","                #Calculating loss               \n","                loss+=(lossFunction(decoderOutput, targetChars))\n","\n","                decoderInput = topIndeces.squeeze().detach()\n","                #Softmax values\n","                Output.append(decoderInput)\n","                \n","            tensor_2d = torch.stack(Output)\n","            Output = tensor_2d.t()\n","            \n","            #Summing up the equal values to find accuracy\n","            train_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n","            train_loss += (loss.item()/sequenceLen)\n","            \n","            encoderOptimizer.zero_grad()\n","            decoderOptimizer.zero_grad()\n","            \n","            #Backward prop\n","            loss.backward()\n","            encoderOptimizer.step()\n","            decoderOptimizer.step()\n","            \n","        epoch=epoch+1\n","            \n","        #print(\"train_accuracy\",train_accuracy/512)\n","        #print(\"train_loss\",train_loss)\n","        #wandb.log({'train_accuracy':train_accuracy/512})\n","        #wandb.log({'train_loss':train_loss})\n","        validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection) #Evaluate valid accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#For running on test data.\n","data3 = pre_processing_validation(copy.copy(test_input),copy.copy(test_output))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T05:03:39.010912Z","iopub.status.busy":"2024-05-17T05:03:39.010274Z"},"trusted":true},"outputs":[],"source":["def main_fun():\n","    wandb.init(project ='vanillaRNN')\n","    params = wandb.config\n","    with wandb.init(project = 'vanillaRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n","        train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n","    \n","sweep_params = {\n","    'method' : 'bayes',\n","    'name'   : 'VanillaRNN',\n","    'metric' : {\n","        'goal' : 'maximize',\n","        'name' : 'validation_accuracy',\n","    },\n","    'parameters' : {\n","        'cellType' : {'values' : ['GRU','RNN','LSTM'] } ,\n","        'epochs'  : {'values': [10,15]},\n","        'batchsize' : {'values' : [32,64]},\n","        'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n","        'embSize':{'values':[16,32,64]},\n","        'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n","        'bidirection' : {'values' : ['no','Yes']},\n","        'dropout' : {'values' : [0,0.2,0.3]},\n","        'encoderLayers':{'values':[1,5,10]},\n","        'decoderLayers' : {'values' : [1,5,10]},\n","        'optimizer':{'values' : ['Adam','Nadam']},\n","        'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n","    }\n","}\n","sweepId = wandb.sweep(sweep_params,project = 'VanillaRNN')\n","wandb.agent(sweepId,function =main_fun)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5020607,"sourceId":8430586,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
